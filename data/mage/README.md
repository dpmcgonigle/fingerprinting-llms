# MAGE: Machine-generated Text Detection in the Wild
This is a comprehensive testbed for LLM detection built by gathering texts from diverse human writings and
texts generated by different LLMs

## Data
You can download the data from https://huggingface.co/datasets/yaful/MAGE.

## Human Text (from https://arxiv.org/pdf/2305.13242)
Data Sourcing. We collect human-written texts
from a set of benchmark datasets, which cover
diverse writing tasks including: (1) Opinion
statement: 804 opinion statements from the
/r/ChangeMyView (CMV) Reddit subcommunity
(Tan et al., 2016) and 1,000 reviews from Yelp
dataset (Zhang et al., 2015); (2) News article writing: 1,000 news articles from XSum
(Narayan et al., 2018) and 777 news articles from
TLDR_news*
(TLDR); (3) Question answering:
1,000 answers from the ELI5 dataset (Fan et al.,
2019); (4) Story generation: 1,000 prompted stories
from the Reddit WritingPrompts (WP) dataset (Fan
et al., 2018) and 1,000 stories from ROCStories
Corpora (ROC) (Mostafazadeh et al., 2016); (5)
Commonsense reasoning: 1,000 sentence sets for
reasoning from HellaSwag (Zellers et al., 2019a);
(6) Knowledge illustration: 1,000 Wikipedia paragraphs from SQuAD contexts (Rajpurkar et al.,
2016); (7) Scientific writing: 1,000 abstracts of scientific articles from SciXGen (Chen et al., 2021a). 

## LLM Text (from https://arxiv.org/pdf/2305.13242)
Model sets. We aim to adopt a wide spectrum of representative large language models
(LLMs) to construct machine-generated texts.
In particular, we consider 27 LLMs in this
work: OpenAI GPT (text-davinci-002/textdavinci-003/gpt-turbo-3.5) (Brown et al., 2020),
LLaMA (6B/13B/30B/65B) (Touvron et al., 2023),
GLM-130B (Zeng et al., 2022), FLAN-T5
(small/base/large/xl/xxl) (Chung et al., 2022),
OPT (125M/350M/1.3B/2.7B/6.7B/13B/30B/iml1.3B/iml-30B) (Zhang et al., 2022a), BigScience
(T0-3B/T0-11B/BLOOM-7B1) (Sanh et al., 2022;
BigScience, 2023) and EleutherAI (GPT-J-6B and
GPT-NeoX-20B) (Wang and Komatsuzaki, 2021;
Black et al., 2022).
