% =============================
% Draft Report Template (LaTeX)
% =============================
% Requirements covered:
% 1) Title Page (title, your name, Advisor's name)
% 2) Abstract (≤150 words)
% 3) Acknowledgments
% 4) Table of Contents (includes Bibliography and Appendices)
% 5) Main text (sections)
% 6) References
% 7) Appendices
% Methods subdivided into: dataset curation, analysis of distributions, analysis of signals

\documentclass[12pt]{report}

% ---------- Packages ----------
\usepackage[a4paper,margin=1in]{geometry}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{csquotes}
\usepackage{enumitem}
\usepackage{titlesec}
\usepackage{lipsum} % for placeholder text (remove when drafting)

% Bibliography with biblatex (adds Bibliography to TOC via bibintoc)
% If you prefer BibTeX, replace this block with natbib or plain thebibliography
\usepackage[backend=biber,style=ieee,sorting=nyt]{biblatex}
\addbibresource{references.bib}

% ---------- Formatting Tweaks ----------
% Section spacing that's compact but readable
\titlespacing*{\section}{0pt}{2.0ex plus 0.5ex minus 0.2ex}{1.0ex plus 0.2ex}
\titlespacing*{\subsection}{0pt}{1.8ex plus 0.5ex minus 0.2ex}{0.8ex plus 0.2ex}
\titlespacing*{\subsubsection}{0pt}{1.4ex plus 0.3ex minus 0.2ex}{0.6ex plus 0.2ex}

% Clickable links appearance
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  citecolor=blue,
  urlcolor=blue,
  pdfauthor={Daniel McGonigle},
  pdftitle={Fingerprinting Large Language Models with Signal Processing}
}

% Optional: line spacing for readability (uncomment if desired)
% \onehalfspacing

% ---------- Title Data ----------
\title{\textbf{Fingerprinting Large Language Models with Signal Processing}}
\author{Daniel McGonigle \\[4pt] Advisor: Dr. Joris Roos}
\date{\today}

\begin{document}

% ---------- Title Page ----------
\begin{titlepage}
    \centering
    {\Huge \bfseries Fingerprinting Large Language Models with Signal Processing\\[12pt]}
    \vspace{1.5cm}
    {\Large Daniel McGonigle\\[6pt]}

    {\large Advisor: Dr. Joris Roos}\\[12pt]

    {\large University of Massachusetts Lowell, Mathematics Department}\\[2pt]
    {\large Lowell, MA}\\[18pt]

    {\large \today}
    \vfill
\end{titlepage}

% Front matter uses roman numerals
\pagenumbering{roman}

% ---------- Abstract (≤150 words) ----------
\begin{abstract}
This project investigates whether large language models (LLMs) exhibit measurable statistical and spectral differences from human-generated text. Using token-level log-probability sequences for both human- and machine-generated text, we analyze distributional and signal-based features to identify potential “fingerprints” of model generation. Power-spectral densities, wavelet decompositions, and entropy measures were computed for human- and machine-authored corpora, revealing some measurable deviations in frequency dynamics between human and machine-generated sources. A classification model trained on these spectral representations achieved limited success in discriminating between human and model text, particularly when the same model used to generate the text provided the log-probability signal. These findings suggest that there may be merit in frequency-domain analysis as a means to detect text generated by advanced LLMs. 
\end{abstract}

% ---------- Acknowledgments ----------
\section*{Acknowledgments}
I would like to express my deepest gratitude to Dr. Joris Roos for his guidance, encouragement, and invaluable feedback throughout this project.  

% Ensure unnumbered sections appear in TOC
\addcontentsline{toc}{section}{Acknowledgments}

% ---------- Table of Contents ----------
\tableofcontents
\clearpage

% Switch to arabic page numbering for main text
\pagenumbering{arabic}

% ---------- Main Text ----------

\chapter{Introduction}
Since the release of GPT-3 ~\cite{brown2020gpt3}, large language models (LLMs) based on transformer architecture have revolutionized natural language processing by enabling fluent text generation that can closely mimic human style and reasoning. As the distinction between human- and machine-authored text becomes increasingly subtle, reliable methods for text that was produced by LLMs has become a significant challenge. Furthermore, there is value in attributing text to specific models, or identifying "fingerprints" imparted by particular models that aid in attribution. Applications range from academic integrity and misinformation tracking to model auditing and authenticity verification.

In this project, we explore an alternative perspective: that each model’s generation process may leave a measurable spectral signature when its token probability sequence is treated as a signal. Specifically, we hypothesize that human and model text differ in the temporal and frequency-domain characteristics of these probability signals due to differences in attention dynamics and sampling noise.

To investigate this hypothesis, we conducted a systematic comparison between human-written and LLM-generated text using Fourier analysis and wavelet transforms applied to token log-probability sequences. The analysis focused on identifying characteristic frequency bands, entropy levels, and power-spectrum shapes that could distinguish machine- from human-generated text. Complementary statistical and distributional metrics aimed at probing frequency characteristics were also used to evaluate the separability of these groups in a non-spectral space.

There are two goals in this work: The first goal is to assess whether frequency-domain analysis provides meaningful discriminatory power between human and model text. The second is to establish a foundation for spectral fingerprinting, with the hope that this can be done in a model-agnostic manner. The findings of this study demonstrate some promising signal-level regularities that suggest LLMs possess spectral patterns across generations, motivating future research into cross-model generalization, temporal dynamics of attention mechanisms, and the integration of spectral features into broader model-audit frameworks.

\chapter{Background and Related Work}
LLMs are autoregressive neural networks trained to predict the next token in a sequence given all preceding context. During generation, each output token is sampled from a probability distribution $P(t_i \mid t_{<i})$, representing the model's estimated likelihood of possible continuations at position $i$. These token-level probabilities capture a model's evolving internal state and confidence: when the model is highly certain, the distribution is sharply peaked; when uncertain, it is flatter. The logarithm of these probabilities, or \emph{log-probabilities}, are particularly useful because they linearize multiplicative relationships, stabilize numerical variation, and directly reflect the additive structure of sequence likelihoods.

In this research, these per-token log-probabilities are treated not merely as statistical outcomes but as a \emph{temporal signal} that evolves as the model generates text. Each step in generation corresponds to a new sample in a discrete-time series whose fluctuations encode the model's shifting certainty, stylistic rhythm, and contextual transitions. This framing allows the use of signal-processing tools---such as Fourier and wavelet transforms---to examine structure in the \emph{frequency domain} rather than only the token-distribution domain. If model outputs differ systematically from human writing in the smoothness, periodicity, or spectral composition of their log-probability sequences, these differences can be interpreted as latent \emph{fingerprints} of the model's internal generative dynamics. By analyzing log-probabilities as signals, we aim to uncover whether LLMs exhibit distinctive frequency-domain patterns that remain stable across text samples and model families, providing a potential foundation for model attribution and authenticity detection.

Most existing detection techniques focus on lexical or syntactic cues, statistical irregularities such as word, phrase or punctuation probabilities, or leveraging neural networks as in ~\cite{wu2023survey}. Some approaches targeting specific data domains have showed limited success, as in DetectRL~\cite{wu2024detectrl}. Zhang et al.~\cite{zhang2024zeroshot} introduced a zero-shot detection approach that operates directly on token probability distributions, showing that simple statistical measures such as likelihood variance and divergence between human and model token-prob histograms can achieve strong performance (AUROC $\approx 0.9$) when distinguishing GPT-3 and ChatGPT text from human writing. Yet these methods often fail to generalize across models or fine-tuning conditions. 

\chapter{Methods}
% Describe how you conducted the project. Keep it reproducible.

\section{Dataset Curation}
% Sources, inclusion/exclusion criteria, cleaning, splits, and any labeling.
% Data governance/ethics if applicable. Versioning and tooling.
% \lipsum[5]

\section{Analysis of Distributions}
% Statistical characterizations: token/prob distributions, ECDFs, divergence metrics
% (e.g., KL, JS, Wasserstein), calibration checks, baselines, and error analysis.
% \lipsum[6]

\section{Analysis of Signals}
% Temporal/spectral techniques: Fourier, wavelets, power spectra, entropy, stationarity
% assumptions, windowing, parameter choices, and validation protocols.
% \lipsum[7]

\chapter{Results}
% Present the outcomes clearly with tables/figures. Emphasize findings that answer your
% research questions. Include effect sizes/uncertainty where applicable.
% \lipsum[8]

\chapter{Discussion}
% Interpret the results: what they mean, why they matter, limitations, and threats to
% validity. Contrast with expectations and possible confounders.
% \lipsum[9]

\chapter{Conclusion and Future Work}
% Concise recap of what you did and learned. Short forward-looking section proposing
% concrete next steps and extensions.
% \lipsum[10]

% ---------- References ----------
\clearpage
\phantomsection
\printbibliography[heading=bibintoc,title={References}]

% ---------- Appendices ----------
\appendix

\chapter{Additional Tables and Figures}
% Extended results, full-size figures, or supplementary plots.
% \lipsum[11]

\chapter{Implementation Details}
% Hyperparameters, environment specs, reproducibility notes, or pseudocode.
% \lipsum[12]

\end{document}

