#   This is the file used to create the environment to run vllm
#   This is just for serving LLMs
fastapi==0.119.0
llvmlite==0.44.0
starlette==0.48.0
tiktoken==0.7.0
tokenizers==0.22.1
torch==2.8.0
transformers==4.56.2
uvicorn==0.38.0
vllm==0.11.0
